{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('../dataset/train_balance.csv', quotechar='\"', encoding='utf8',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1         is upset that he can't update his Facebook by ...\n",
       "2         @Kenichan I dived many times for the ball. Man...\n",
       "3           my whole body feels itchy and like its on fire \n",
       "4         @nationwideclass no, it's not behaving at all....\n",
       "5                             @Kwesidei not the whole crew \n",
       "6                                               Need a hug \n",
       "7         @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "8                      @Tatiana_K nope they didn't have it \n",
       "9                                 @twittera que me muera ? \n",
       "10              spring break in plain city... it's snowing \n",
       "11                               I just re-pierced my ears \n",
       "12        @caregiving I couldn't bear to watch it.  And ...\n",
       "13        @octolinz16 It it counts, idk why I did either...\n",
       "14        @smarrison i would've been the first, but i di...\n",
       "15        @iamjazzyfizzle I wish I got to watch it with ...\n",
       "16        Hollis' death scene will hurt me severely to w...\n",
       "17                                     about to file taxes \n",
       "18        @LettyA ahh ive always wanted to see rent  lov...\n",
       "19        @FakerPattyPattz Oh dear. Were you drinking ou...\n",
       "20        @alydesigns i was out most of the day so didn'...\n",
       "21        one of my friend called me, and asked to meet ...\n",
       "22         @angry_barista I baked you a cake but I ated it \n",
       "23                   this week is not going as i had hoped \n",
       "24                               blagh class at 8 tomorrow \n",
       "25           I hate when I have to call and wake people up \n",
       "26        Just going to cry myself to sleep after watchi...\n",
       "27                                   im sad now  Miss.Lilly\n",
       "28        ooooh.... LOL  that leslie.... and ok I won't ...\n",
       "29        Meh... Almost Lover is the exception... this t...\n",
       "                                ...                        \n",
       "497825    @jconley21 Near MI, you're now smelling a good...\n",
       "497826    @Not_A_Kid She gave it to him i think. And he ...\n",
       "497827    @greggarbo One of my favorite songs.  australi...\n",
       "497828    @Pam97 Hi Pam!  I'm writing too!  HAPPY FRIDAY!! \n",
       "497829    Good start to the morning so far. A little mor...\n",
       "497830    @ladygaga Next Wednesday Night..12.05pm i thin...\n",
       "497831    (@xxTaSh) that I闁跨喓涓?excited for his album and...\n",
       "497832                     @rmccue NAD's. You got me there \n",
       "497833           @jellybeanhorror if this is love! amazing \n",
       "497834    @mohd_athar thanks Athar  You too, have a good...\n",
       "497835    @CherylHarrison If @tokenliberal is wearing a ...\n",
       "497836    @shakeappeal Ha! No, not your Mom, my girlfrie...\n",
       "497837    when you get home today, but that's just a sid...\n",
       "497838    @raginaphalange Anyway the song keeps on playi...\n",
       "497839    @elavoca you're probably right  You know what ...\n",
       "497840    Were having an ice cream party today  catered ...\n",
       "497841    #followfriday @chovaleoni she's hilarious, wit...\n",
       "497842    @littlemissmessy Sounds like a good weekend to...\n",
       "497843    @pollyalida lots of cheap golf shirts, too.  I...\n",
       "497844    For my friends who may not know... #FF means f...\n",
       "497845                  home from the beach, and oh so tan \n",
       "497846    Happy Friday everyone! It's going to be a fant...\n",
       "497847    @jenciTN Why hello my dear! Are you melting th...\n",
       "497848    going to the citiy  oh god i闁跨喓涓?such a shopah...\n",
       "497849    just in from bein at my grannys. Got another d...\n",
       "497850                           @efink my gegegeneration! \n",
       "497851           is about to go out in the lovely sunshine \n",
       "497852    babysitting   It's fun because i get to watch ...\n",
       "497853    @CharlesGary I think so too, hopefully we have...\n",
       "497854         Starter som konsulent hos Atea 1. september \n",
       "Name: 1, Length: 497855, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=data[0]\n",
    "text=data[1]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      - awww  that's a bummer   you shoulda got da...\n",
      "1    is upset that he can't update his facebook by ...\n",
      "2     i dived many times for the ball  managed to s...\n",
      "3      my whole body feels itchy and like its on fire \n",
      "4     no  it's not behaving at all  i'm mad  why am...\n",
      "Name: text_processed, dtype: object\n",
      "0           - awww  that's a bummer   you shoulda got da...\n",
      "1         is upset that he can't update his facebook by ...\n",
      "2          i dived many times for the ball  managed to s...\n",
      "3           my whole body feels itchy and like its on fire \n",
      "4          no  it's not behaving at all  i'm mad  why am...\n",
      "5                                       not the whole crew \n",
      "6                                               need a hug \n",
      "7          hey  long time no see  yes   rains a bit  onl...\n",
      "8                              _k nope they didn't have it \n",
      "9                                           que me muera   \n",
      "10              spring break in plain city    it's snowing \n",
      "11                               i just re-pierced my ears \n",
      "12         i couldn't bear to watch it   and i thought t...\n",
      "13        16 it it counts  idk why i did either  you nev...\n",
      "14         i would've been the first  but i didn't have ...\n",
      "15         i wish i got to watch it with you   i miss yo...\n",
      "16        hollis' death scene will hurt me severely to w...\n",
      "17                                     about to file taxes \n",
      "18         ahh ive always wanted to see rent  love the s...\n",
      "19         oh dear  were you drinking out of the forgott...\n",
      "20         i was out most of the day so didn't get much ...\n",
      "21        one of my friend called me  and asked to meet ...\n",
      "22               _barista i baked you a cake but i ated it \n",
      "23                   this week is not going as i had hoped \n",
      "24                               blagh class at 8 tomorrow \n",
      "25           i hate when i have to call and wake people up \n",
      "26        just going to cry myself to sleep after watchi...\n",
      "27                                   im sad now  miss lilly\n",
      "28        ooooh     lol  that leslie     and ok i won't ...\n",
      "29        meh    almost lover is the exception    this t...\n",
      "                                ...                        \n",
      "497825    21 near mi  you're now smelling a good smell  ...\n",
      "497826    _a_kid she gave it to him i think  and he read...\n",
      "497827     one of my favorite songs   australia games ho...\n",
      "497828        97 hi pam   i'm writing too   happy friday   \n",
      "497829    good start to the morning so far  a little mor...\n",
      "497830     next wednesday night  12 05pm i think  channe...\n",
      "497831    () that i闁跨喓涓 excited for his album and stuff ...\n",
      "497832                             nad's  you got me there \n",
      "497833                            if this is love  amazing \n",
      "497834      _athar thanks athar  you too  have a good one  \n",
      "497835     if  is wearing a burger king crown on his pro...\n",
      "497836         ha  no  not your mom  my girlfriend's mom   \n",
      "497837    when you get home today  but that's just a sid...\n",
      "497838     anyway the song keeps on playing in my head  ...\n",
      "497839     you're probably right  you know what i mean  ...\n",
      "497840    were having an ice cream party today  catered ...\n",
      "497841              she's hilarious  witty &amp; wonderful \n",
      "497842                    sounds like a good weekend to me \n",
      "497843     lots of cheap golf shirts  too   including a ...\n",
      "497844    for my friends who may not know     means foll...\n",
      "497845                  home from the beach  and oh so tan \n",
      "497846    happy friday everyone  it's going to be a fant...\n",
      "497847     why hello my dear  are you melting things up ...\n",
      "497848    going to the citiy  oh god i闁跨喓涓 such a shopah...\n",
      "497849    just in from bein at my grannys  got another d...\n",
      "497850                                  my gegegeneration  \n",
      "497851           is about to go out in the lovely sunshine \n",
      "497852    babysitting   it's fun because i get to watch ...\n",
      "497853     i think so too  hopefully we have an expert i...\n",
      "497854         starter som konsulent hos atea 1  september \n",
      "Name: text_processed, Length: 497855, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Uncomment the line below if loading from previously saved CSV\n",
    "\n",
    "# Remove punctuation\n",
    "\n",
    "\n",
    "# Remove unnecessary line breaks\n",
    "data['text_processed'] = text.map(lambda x: re.sub(r\"\\n\", '', x))\n",
    "# Convert the titles to lowercase\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: x.lower())\n",
    "# Clean the url\n",
    "\n",
    "\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: re.sub(r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})', '', x))\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: re.sub('https?', ' ', x))\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: re.sub(r'(@[A-Za-z]+)\"?', '', x))\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: re.sub(r'(#[A-Za-z]+)\"?', '', x))\n",
    "data['text_processed'] = data['text_processed'].map(lambda x: re.sub('[,\\\\.!?]', ' ', x))\n",
    "\n",
    "\n",
    "\n",
    "# Print out the first rows \n",
    "print(data['text_processed'].head())\n",
    "\n",
    "# Removing duplicate tweets?\n",
    "unique_tweets = list(set(list(data['text_processed'].values)))\n",
    "unique_tweets = [t for t in unique_tweets if t]\n",
    "\n",
    "print(data['text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AW\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Do you want to modify this by adding more stop words?\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "  for sentence in sentences:\n",
    "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "  return [[word for word in simple_preprocess(str(doc)) \n",
    "    if word not in stop_words] for doc in texts]\n",
    "\n",
    "\n",
    "data1 = data.text_processed.values.tolist()\n",
    "\n",
    "data_words = list(sent_to_words(data1))\n",
    "\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index=0\n",
    "wordlist = []\n",
    "score_list = []\n",
    "word_statistic = {}\n",
    "word_statistic_count = {}\n",
    "sentence_unique={}\n",
    "\n",
    "for sentence in data_words:\n",
    "    sentence_string=[]\n",
    "    sentence_string=''.join(sentence)\n",
    "    if sentence_string not in sentence_unique:\n",
    "        sentence_unique[sentence_string] = 1\n",
    "        score=label[index]/2-1\n",
    "        for word in sentence:\n",
    "            if word in word_statistic:\n",
    "                word_statistic[word] += score\n",
    "                word_statistic_count[word] += 1\n",
    "            else:\n",
    "                word_statistic[word] = score\n",
    "                word_statistic_count[word] = 1\n",
    "    index+=1\n",
    "for word in word_statistic:\n",
    "    if word_statistic_count[word]>=20:\n",
    "        wordlist.append(word)\n",
    "        score_list.append(word_statistic[word]/word_statistic_count[word]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww</td>\n",
       "      <td>-0.251744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bummer</td>\n",
       "      <td>-0.837472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shoulda</td>\n",
       "      <td>-0.584158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>got</td>\n",
       "      <td>-0.130261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david</td>\n",
       "      <td>0.197581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>carr</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>third</td>\n",
       "      <td>-0.054152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0.102316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>upset</td>\n",
       "      <td>-0.856436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>update</td>\n",
       "      <td>0.023381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>facebook</td>\n",
       "      <td>0.114875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texting</td>\n",
       "      <td>0.028037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>might</td>\n",
       "      <td>0.030921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cry</td>\n",
       "      <td>-0.756560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>result</td>\n",
       "      <td>-0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>school</td>\n",
       "      <td>-0.265951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>today</td>\n",
       "      <td>-0.124059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>also</td>\n",
       "      <td>0.084808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>blah</td>\n",
       "      <td>-0.592453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>many</td>\n",
       "      <td>-0.070901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>times</td>\n",
       "      <td>-0.047294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ball</td>\n",
       "      <td>-0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>managed</td>\n",
       "      <td>-0.074534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>save</td>\n",
       "      <td>-0.094290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rest</td>\n",
       "      <td>0.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>go</td>\n",
       "      <td>-0.257496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>whole</td>\n",
       "      <td>-0.141640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>body</td>\n",
       "      <td>-0.320293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>feels</td>\n",
       "      <td>-0.335798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>itchy</td>\n",
       "      <td>-0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10762</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10763</th>\n",
       "      <td>hints</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10764</th>\n",
       "      <td>cavaliers</td>\n",
       "      <td>-0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10765</th>\n",
       "      <td>optimism</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10766</th>\n",
       "      <td>boundaries</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10767</th>\n",
       "      <td>honesty</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10768</th>\n",
       "      <td>haaa</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10769</th>\n",
       "      <td>grader</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10770</th>\n",
       "      <td>cav</td>\n",
       "      <td>-0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>paulo</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10772</th>\n",
       "      <td>kellie</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10773</th>\n",
       "      <td>wordsaftersex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10774</th>\n",
       "      <td>sweeter</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10775</th>\n",
       "      <td>applies</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10776</th>\n",
       "      <td>interactive</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10777</th>\n",
       "      <td>quoted</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10778</th>\n",
       "      <td>fuzzball</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10779</th>\n",
       "      <td>venus</td>\n",
       "      <td>-0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10780</th>\n",
       "      <td>subo</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10781</th>\n",
       "      <td>thankies</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10782</th>\n",
       "      <td>spymaster</td>\n",
       "      <td>-0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>hiiii</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>domination</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>heavenly</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>sow</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>beached</td>\n",
       "      <td>-0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>shaheen</td>\n",
       "      <td>-0.581395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>feat</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10790</th>\n",
       "      <td>idiotat</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10791</th>\n",
       "      <td>nks</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1\n",
       "0               awww -0.251744\n",
       "1             bummer -0.837472\n",
       "2            shoulda -0.584158\n",
       "3                got -0.130261\n",
       "4              david  0.197581\n",
       "5               carr  0.200000\n",
       "6              third -0.054152\n",
       "7                day  0.102316\n",
       "8              upset -0.856436\n",
       "9             update  0.023381\n",
       "10          facebook  0.114875\n",
       "11           texting  0.028037\n",
       "12             might  0.030921\n",
       "13               cry -0.756560\n",
       "14            result -0.024155\n",
       "15            school -0.265951\n",
       "16             today -0.124059\n",
       "17              also  0.084808\n",
       "18              blah -0.592453\n",
       "19              many -0.070901\n",
       "20             times -0.047294\n",
       "21              ball -0.078125\n",
       "22           managed -0.074534\n",
       "23              save -0.094290\n",
       "24              rest  0.030120\n",
       "25                go -0.257496\n",
       "26             whole -0.141640\n",
       "27              body -0.320293\n",
       "28             feels -0.335798\n",
       "29             itchy -0.794521\n",
       "...              ...       ...\n",
       "10762     conspiracy  0.727273\n",
       "10763          hints  0.500000\n",
       "10764      cavaliers -0.857143\n",
       "10765       optimism  0.714286\n",
       "10766     boundaries  0.833333\n",
       "10767        honesty  0.416667\n",
       "10768           haaa  0.655172\n",
       "10769         grader  0.238095\n",
       "10770            cav -0.619048\n",
       "10771          paulo  0.200000\n",
       "10772         kellie  0.750000\n",
       "10773  wordsaftersex  0.000000\n",
       "10774        sweeter  0.840000\n",
       "10775        applies  0.636364\n",
       "10776    interactive  0.800000\n",
       "10777         quoted  0.500000\n",
       "10778       fuzzball  0.937500\n",
       "10779          venus -0.363636\n",
       "10780           subo -1.000000\n",
       "10781       thankies  0.809524\n",
       "10782      spymaster -0.909091\n",
       "10783          hiiii  0.809524\n",
       "10784     domination  0.809524\n",
       "10785       heavenly  0.866667\n",
       "10786            sow -0.600000\n",
       "10787        beached -0.809524\n",
       "10788        shaheen -0.581395\n",
       "10789           feat  0.941176\n",
       "10790        idiotat  1.000000\n",
       "10791            nks  1.000000\n",
       "\n",
       "[10792 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lexicon_list={}\n",
    "#for i in range(len(wordlist)):\n",
    "    #lexicon_list[wordlist[i]]=score_list[i]\n",
    "my_lexicon=pd.DataFrame(wordlist,index=None)\n",
    "my_lexicon[1]=score_list\n",
    "my_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lexicon.to_csv(\"my_lexicon.txt\", index=None,header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
